import re
import csv
import os
import pandas as pd

# --- CONFIGURA√á√ÉO ---

# 1. Coloque aqui o caminho do seu arquivo de entrada
ARQUIVO_ENTRADA = 'CNPJresults_findStudio 3.txt'

# 2. Nomes dos arquivos de sa√≠da que ser√£o gerados
ARQUIVO_SAIDA_AJUSTES = 'analise_ajustes_criticos.xlsx'
ARQUIVO_SAIDA_DESCARTES = 'analise_descartes.xlsx'
ARQUIVO_SAIDA_DESCARTES_OFICIAIS = 'analise_descartes_oficiais.xlsx'
ARQUIVO_SAIDA_PRECIFICACAO = 'analise_precificacao_proposta.xlsx'
ARQUIVO_SAIDA_DESCARTES_EXTRACAO = 'analise_descartes_extracao_simples.xlsx'
ARQUIVO_SAIDA_RESUMO = 'analise_resumo_criticos_oficiais.xlsx'

# 3. Arquivo com os termos de busca a serem analisados
ARQUIVO_TERMOS = 'CNPJ 1.csv'

# --- ATIVIDADES BASE DO PROJETO ---
# Esfor√ßos fixos para atividades que independem da contagem de pontos de c√≥digo,
# refletindo o escopo completo do projeto de adequa√ß√£o ao CNPJ alfanum√©rico.
ATIVIDADES_BASE_PROJETO = {
    "GERENCIAMENTO_PROJETO": {
        "nome": "Gerenciamento e Planejamento",
        "esforco_dev": 80, "esforco_testes": 0,
        "descricao": "Coordena√ß√£o do projeto, reuni√µes, planejamento de sprints e acompanhamento das entregas."
    },
    "ANALISE_DETALHADA": {
        "nome": "An√°lise de Requisitos e Arquitetura da Solu√ß√£o",
        "esforco_dev": 60, "esforco_testes": 0,
        "descricao": "An√°lise detalhada do novo c√°lculo de DV, regras de neg√≥cio, e defini√ß√£o da arquitetura da solu√ß√£o central."
    },
    "SOLUCAO_CENTRAL": {
        "nome": "Desenvolvimento da Solu√ß√£o Central",
        "esforco_dev": 120, "esforco_testes": 40,
        "descricao": "Cria√ß√£o e testes das fun√ß√µes centrais de valida√ß√£o, formata√ß√£o e c√°lculo de DV para o CNPJ alfanum√©rico."
    },
    "ATUALIZACAO_DOCUMENTACAO": {
        "nome": "Atualiza√ß√£o de Documenta√ß√£o T√©cnica e Manuais",
        "esforco_dev": 40, "esforco_testes": 0,
        "descricao": "Revis√£o e atualiza√ß√£o de manuais t√©cnicos, schemas (XML, etc.), e documenta√ß√£o de APIs."
    },
    "MIGRACAO_CODIGO_BARRAS": {
        "nome": "An√°lise e Migra√ß√£o do C√≥digo de Barras",
        "esforco_dev": 24, "esforco_testes": 8,
        "descricao": "An√°lise do impacto e implementa√ß√£o da migra√ß√£o do padr√£o de c√≥digo de barras de CODE-128C para CODE-128A."
    },
    "HOMOLOGACAO_TESTES_FINAIS": {
        "nome": "Fase de Homologa√ß√£o e Testes Integrados",
        "esforco_dev": 80, "esforco_testes": 160,
        "descricao": "Ciclo completo de testes de homologa√ß√£o (UAT), testes de regress√£o e prepara√ß√£o do ambiente de produ√ß√£o."
    }
}

# --- CATEGORIAS PARA AJUSTE DE C√ìDIGO ---
# Mantidas para gerar a estimativa de esfor√ßo de refatora√ß√£o.
CATEGORIAS_AJUSTE_CODIGO = {
    "VALIDACAO_ENTRADA": {
        "nome": "Valida√ß√£o e Entrada de Dados",
        "descricao": "Pontos que validam entrada de CNPJ - ser√£o ajustados para usar fun√ß√£o central",
        "esforco_base": 56, "esforco_testes": 22,
        "observacao": "Implementa√ß√£o de fun√ß√£o central + ajustes pontuais"
    },
    "FORMATACAO_EXIBICAO": {
        "nome": "Formata√ß√£o e Exibi√ß√£o",
        "descricao": "Pontos que formatam CNPJ para exibi√ß√£o - usar√£o fun√ß√£o central",
        "esforco_base": 30, "esforco_testes": 10,
        "observacao": "Substitui√ß√£o por chamadas √† fun√ß√£o central"
    },
    "LOGICA_NEGOCIO": {
        "nome": "L√≥gica de Neg√≥cio Espec√≠fica",
        "descricao": "Pontos com l√≥gica espec√≠fica que precisam revis√£o manual",
        "esforco_base": 120, "esforco_testes": 48,
        "observacao": "An√°lise caso a caso, reengenharia e testes espec√≠ficos"
    },
    "CHAMADA_SUBROTINA": {
        "nome": "Chamada de Sub-rotina",
        "descricao": "Pontos que chamam sub-rotinas relacionadas, precisam de an√°lise de impacto.",
        "esforco_base": 40, "esforco_testes": 16,
        "observacao": "An√°lise do fluxo de dados de entrada e sa√≠da da sub-rotina."
    },
    "ESTRUTURA_DADOS": {
        "nome": "Estrutura de Dados",
        "descricao": "Ajustes em banco de dados, √≠ndices e consultas",
        "esforco_base": 24, "esforco_testes": 12,
        "observacao": "Revis√£o de tipos de dados, √≠ndices, performance e migra√ß√£o"
    },
    "REVISAO_MANUAL": {
        "nome": "Revis√£o Manual Necess√°ria",
        "descricao": "Linhas que n√£o se encaixam em padr√µes conhecidos e exigem an√°lise",
        "esforco_base": 2, "esforco_testes": 1, # Custo por ponto
        "observacao": "An√°lise manual para determinar a categoria correta e o impacto"
    }
}

# --- REGRAS DE DESCARTE DE ALTA CONFIAN√áA ---
# Se uma linha corresponder a qualquer uma destas regras, ser√° descartada.
REGRAS_DESCARTE_CONFIANCA = [
    # Regra unificada para coment√°rios que ser√° verificada com uma exce√ß√£o
    ("Coment√°rio", r"^\s*(;+|//)"),
    # Movida para cima para ter prioridade sobre regras mais gen√©ricas
    ("Extra√ß√£o Simples de Substring", r"(\$E|\$EXTRACT)\s*\(\s*\bVARIAVEL\b"),
    ("String Literal", r'".*\bVARIAVEL\b.*"'),
    # Regra aprimorada para ser mais espec√≠fica e evitar descartar atribui√ß√µes que usam a vari√°vel
    ("Atribui√ß√£o Simples (de vari√°vel)", r"^\s*(S|Set)\s+\w+\s*=\s*\bVARIAVEL\b\s*($|;|,|!)"),
    # Regra aprimorada para permitir propriedades de objeto (ponto) e vari√°veis com '%'
    ("Atribui√ß√£o Simples (para vari√°vel)", r"^\s*(S|Set)\s+\bVARIAVEL\b\s*=\s*[%.\w]+\s*($|;|,|!)"),
    # Regra expandida para cobrir atribui√ß√µes em lista, como S ALT=0,CCLI=""
    ("Set para Vazio", r'^\s*(S|Set)\s+.*\bVARIAVEL\b\s*=\s*""|,\s*\bVARIAVEL\b\s*=\s*""'),
    # Nova regra, focada apenas na compara√ß√£o
    ("Compara√ß√£o com Vazio", r"if\s+'?\bVARIAVEL\b'?\s*=\s*"""),
    # Nova regra para compara√ß√£o com strings fixas
    ("Compara√ß√£o com String Fixa", r"^\s*(I|If)\s+'?\bVARIAVEL\b'?\s*=\s*"".*"""),
    ("Uso como Par√¢metro Simples", r"(\(|,)\s*\bVARIAVEL\b\s*(\)|,)"),
    ("Par√¢metro em Chamada de M√©todo/Fun√ß√£o", r"(##class\(|##super\(|\$\$\w+\^)\([^)]*\bVARIAVEL\b[^)]*\)"),
    ("Chamada de Rotina (Do)", r"^\s*Do\s+.*\^.*\bVARIAVEL\b"),
    ("Uso em $ORDER", r"\$O\s*\(.*\bVARIAVEL\b"),
    # Nova regra para o comando Kill
    ("Comando Kill", r"^\s*(K|Kill)\s+.*?\bVARIAVEL\b"),
    # Regra aprimorada para incluir a abrevia√ß√£o 'N' e ser mais precisa
    ("Declara√ß√£o New", r"^\s*(N|New)\s+.*?\bVARIAVEL\b"),
    ("Verifica√ß√£o de Exist√™ncia ($D, $G)", r"(if\s+\$G|\$D)\(.*\bVARIAVEL\b"),
]

# --- REGRAS PARA IDENTIFICAR AJUSTES CR√çTICOS ---
# Todas as linhas n√£o descartadas ser√£o testadas contra estas regras.
REGRAS_AJUSTE_CRITICO = [
    # --- VALIDA√á√ÉO E ENTRADA ---
    (
        "M√°scara Num√©rica Expl√≠cita", r"\?\d*N", "VALIDACAO_ENTRADA",
        "M√°scara que for√ßa entrada num√©rica - precisa aceitar alfanum√©rico."
    ),
    (
        "Valida√ß√£o de Comprimento", r"\$L(ENGTH)?\s*\(\s*\bVARIAVEL\b.*\)\s*[=<>]\s*(11|14)", "VALIDACAO_ENTRADA",
        "Valida√ß√£o de tamanho fixo - precisa ser flexibilizada."
    ),
    (
        "Convers√£o/Opera√ß√£o Num√©rica", r"(\$NUMBER|\$ZSTRIP)\s*\(\s*\bVARIAVEL\b|\bVARIAVEL\b\s*[\+\-\*\/]\s*\d+|\d+\s*[\+\-\*\/]\s*\bVARIAVEL\b", "VALIDACAO_ENTRADA",
        "Convers√£o para n√∫mero ou opera√ß√£o aritm√©tica - falhar√° com alfanum√©rico."
    ),
    # --- L√ìGICA DE NEG√ìCIO ---
    (
        "Padding com Soma", r"(1000000\d{6,}\s*\+\s*\bVARIAVEL\b|\bVARIAVEL\b\s*\+\s*1000000\d{6,})", "LOGICA_NEGOCIO",
        "T√©cnica de padding com soma para ordena√ß√£o/compara√ß√£o - incompat√≠vel com alfanum√©rico."
    ),
    (
        "Extra√ß√£o com L√≥gica Num√©rica ($E, $EXTRACT)", r"(\$E|\$EXTRACT)\s*\((?=[^)]*\+)[^)]*\bVARIAVEL\b[^)]*\)", "LOGICA_NEGOCIO",
        "Extra√ß√£o de substring combinada com soma, indicando manipula√ß√£o num√©rica."
    ),
    (
        "Parsing com $PIECE", r"\$P(IECE)?\s*\(\s*\bVARIAVEL\b", "LOGICA_NEGOCIO",
        "Parsing da vari√°vel - pode ser afetado se o delimitador for um n√∫mero."
    ),
    # --- FORMATA√á√ÉO E EXIBI√á√ÉO ---
    (
        "Formata√ß√£o Manual para Exibi√ß√£o", r"(\bVARIAVEL\b\s*_\s*""[\.\/\-]"")|W(RITE)?\s+.*\bVARIAVEL\b", "FORMATACAO_EXIBICAO",
        "Formata√ß√£o manual para exibi√ß√£o - deve ser substitu√≠da por fun√ß√£o central."
    ),
    # --- INTEGRA√á√ÉO E REVIS√ÉO MANUAL ---
    (
        "Uso em Contexto de Integra√ß√£o", r"(HTTP|REST|SOAP|XML|JSON|EXPORT|IMPORT|FTP|FILE).*\bVARIAVEL\b", "REVISAO_MANUAL",
        "Uso em contexto de integra√ß√£o. Requer an√°lise manual da compatibilidade."
    ),
    # --- ESTRUTURA DE DADOS ---
    (
        "Uso em Opera√ß√£o de Banco", r"&(SQL|sql)\(.*\bVARIAVEL\b.*\)|(SELECT|INSERT|UPDATE|DELETE|WHERE|ORDER\s+BY).*\bVARIAVEL\b", "ESTRUTURA_DADOS",
        "Opera√ß√£o de banco - verificar tipos de dados, √≠ndices e performance da consulta."
    ),
]


def carregar_termos_busca(caminho_csv):
    """Carrega os termos de busca e seus tipos de um arquivo CSV."""
    if not os.path.exists(caminho_csv):
        print(f"ERRO: Arquivo de termos '{caminho_csv}' n√£o encontrado.")
        return {}
    try:
        df = pd.read_csv(caminho_csv, sep=';', usecols=['termo', 'tipo'], encoding='utf-8', on_bad_lines='skip')
        df.dropna(inplace=True)
        df['termo'] = df['termo'].astype(str).str.strip()
        df['tipo'] = df['tipo'].astype(str).str.strip()
        termos_dict = dict(zip(df['termo'], df['tipo']))
        print(f"{len(termos_dict)} termos de busca √∫nicos carregados de {caminho_csv}")
        return termos_dict
    except Exception as e:
        print(f"ERRO ao ler o arquivo de termos '{caminho_csv}': {e}")
        return {}


def extrair_info_linha(linha):
    """Extrai o nome do arquivo, localizador e o c√≥digo da linha de entrada."""
    # Regex aprimorada para lidar com formatos como:
    # arquivo(loc1): codigo
    # arquivo(loc1)[loc2]: codigo
    match = re.match(r"^(.*?)\((.*?)\)(.*?):\s*(.*)", linha)
    if match:
        arquivo, loc_parens, loc_brackets, codigo = match.groups()
        # Combina as partes do localizador para criar um identificador √∫nico
        localizador = loc_parens.strip() + loc_brackets.strip()
        return arquivo.strip(), localizador, codigo.strip()
    return None, None, None


def classificar_arquivo(nome_arquivo):
    """Adiciona classifica√ß√£o 'Oficiais', 'Scripts' ou 'N√£o Oficiais'."""
    prefixos_oficiais = [
        'dd', 'gap', 'i', 'audit', 'autobasi', 'basico', 'br', 'cbpi', 'csp',
        'estoque', 'faturamento', 'fiscal', 'frete', 'gem', 'ipi', 'ipp',
        'mnemonic', 'precos', 'sistema', 'supervisao', 'tropical', 'tti'
    ]
    nome_arquivo_lower = nome_arquivo.lower()
    if nome_arquivo_lower.startswith('aba'):
        return 'Scripts'
    if any(nome_arquivo_lower.startswith(p) for p in prefixos_oficiais):
        return 'Oficiais'
    return 'N√£o Oficiais'


def checar_descarte(codigo, var_alvo):
    """Verifica se a linha deve ser ignorada com base nas regras de descarte de alta confian√ßa."""
    for motivo, regex in REGRAS_DESCARTE_CONFIANCA:
        regex_var = regex.replace('VARIAVEL', re.escape(var_alvo))
        if re.search(regex_var, codigo, re.IGNORECASE):
            return motivo
    return None


def analisar_ponto_critico(codigo, var_alvo):
    """Aplica as regras de ajuste cr√≠tico e retorna a primeira correspond√™ncia."""
    # Primeiro, verifica regras que n√£o dependem da vari√°vel (globais)
    for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
        if 'VARIAVEL' not in regex:
            if re.search(regex, codigo, re.IGNORECASE):
                return nome, categoria, just, regex

    # Depois, verifica regras vinculadas √† vari√°vel
    for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
        if 'VARIAVEL' in regex:
            regex_var = regex.replace('VARIAVEL', re.escape(var_alvo))
            if re.search(regex_var, codigo, re.IGNORECASE):
                return nome, categoria, just, regex_var

    # Se nenhuma regra cr√≠tica corresponder, classifica para revis√£o manual
    return "Revis√£o Manual Necess√°ria", "REVISAO_MANUAL", "N√£o corresponde a nenhum padr√£o de ajuste ou descarte conhecido.", "N/A"


def gerar_relatorio_precificacao_realista(df_ajustes):
    """Gera relat√≥rio de precifica√ß√£o realista baseado nas atividades base e nos ajustes de c√≥digo."""

    # --- IN√çCIO DA L√ìGICA DE C√ÅLCULO ---
    total_dev = 0
    total_testes = 0
    summary_atividades = []

    # 1. Adicionar Atividades Base do Projeto
    for _, config in ATIVIDADES_BASE_PROJETO.items():
        esforco_dev = config["esforco_dev"]
        esforco_testes = config["esforco_testes"]
        total_dev += esforco_dev
        total_testes += esforco_testes
        summary_atividades.append({
            "Frente de Trabalho": config["nome"],
            "Tipo": "Atividade Base",
            "Pontos Identificados": "N/A",
            "Esfor√ßo Dev (h)": esforco_dev,
            "Esfor√ßo Testes (h)": esforco_testes,
            "Total (h)": esforco_dev + esforco_testes,
            "Observa√ß√£o": config["descricao"],
        })

    # 2. Calcular esfor√ßo para Ajustes de C√≥digo (somente rotinas oficiais)
    df_oficiais = pd.DataFrame()
    if not df_ajustes.empty:
        df_oficiais = df_ajustes[df_ajustes['Classifica√ß√£o'] == 'Oficiais'].copy()
    
    print(f"\nüìä An√°lise de Esfor√ßo de C√ìDIGO focada em ROTINAS OFICIAIS: {len(df_oficiais)} pontos de {len(df_ajustes)} totais.")

    if not df_oficiais.empty:
        contagem_categorias = df_oficiais['Categoria'].value_counts()
        for categoria_id, config in CATEGORIAS_AJUSTE_CODIGO.items():
            pontos = contagem_categorias.get(categoria_id, 0)
            if pontos > 0:
                if categoria_id == "REVISAO_MANUAL":
                    esforco_dev = config["esforco_base"] * pontos
                    esforco_testes = config["esforco_testes"] * pontos
                else:
                    fator_pontos = 1 + (pontos - 1) * 0.05
                    esforco_dev = round(config["esforco_base"] * fator_pontos)
                    esforco_testes = round(config["esforco_testes"] * fator_pontos)

                total_dev += esforco_dev
                total_testes += esforco_testes
                summary_atividades.append({
                    "Frente de Trabalho": config["nome"],
                    "Tipo": "Ajuste de C√≥digo",
                    "Pontos Identificados": pontos,
                    "Esfor√ßo Dev (h)": esforco_dev,
                    "Esfor√ßo Testes (h)": esforco_testes,
                    "Total (h)": esforco_dev + esforco_testes,
                    "Observa√ß√£o": config["observacao"],
                })

    # 3. Gerar Sum√°rio Executivo
    total_geral = total_dev + total_testes
    summary_executivo = [
        {"M√©trica": "Esfor√ßo Desenvolvimento", "Valor": f"{total_dev}h"},
        {"M√©trica": "Esfor√ßo Testes QA", "Valor": f"{total_testes}h"},
        {"M√©trica": "Total Estimado", "Valor": f"{total_geral}h"},
        {"M√©trica": "Estimativa com Buffer (20%)", "Valor": f"{round(total_geral * 1.2)}h"},
        {"M√©trica": "Pontos Cr√≠ticos (Oficiais)", "Valor": len(df_oficiais)},
        {"M√©trica": "Rotinas Oficiais Impactadas", "Valor": df_oficiais['Arquivo'].nunique() if not df_oficiais.empty else 0},
    ]

    # 4. Salvar o relat√≥rio em Excel com m√∫ltiplas abas
    try:
        df_summary = pd.DataFrame(summary_atividades)
        with pd.ExcelWriter(ARQUIVO_SAIDA_PRECIFICACAO, engine='openpyxl') as writer:
            pd.DataFrame(summary_executivo).to_excel(writer, sheet_name='1_Summary_Executivo', index=False)
            df_summary.to_excel(writer, sheet_name='2_Estimativa_Detalhada', index=False)
            if not df_oficiais.empty:
                df_oficiais_detalhe = df_oficiais[['Arquivo', 'Localizador', 'Categoria', 'Padr√£o', 'Justificativa', 'C√≥digo']]
                df_oficiais_detalhe.to_excel(writer, sheet_name='3_Detalhe_Pontos_Oficiais', index=False)
        print(f"Relat√≥rio de precifica√ß√£o salvo em: {ARQUIVO_SAIDA_PRECIFICACAO}")
        print(f"   -> Total Estimado: {total_geral}h | Com Buffer (20%): {round(total_geral * 1.2)}h")
    except Exception as e:
        print(f"ERRO ao salvar relat√≥rio de precifica√ß√£o: {e}")


def gerar_relatorio_resumo(df_ajustes, nome_arquivo):
    """Gera um relat√≥rio de resumo de pontos cr√≠ticos por programa oficial."""
    if df_ajustes.empty:
        print("\nNenhum dado para gerar o relat√≥rio de resumo.")
        return

    df_oficiais = df_ajustes[df_ajustes['Classifica√ß√£o'] == 'Oficiais'].copy()
    if df_oficiais.empty:
        print("\nNenhuma rotina oficial encontrada para o resumo de pontos cr√≠ticos.")
        return

    # Agrupar por arquivo e tipo, contar os pontos
    df_resumo = df_oficiais.groupby(['Arquivo', 'Tipo Programa']).size().reset_index(name='Pontos Cr√≠ticos')
    
    # Ordenar por quantidade de pontos cr√≠ticos
    df_resumo = df_resumo.sort_values(by='Pontos Cr√≠ticos', ascending=False)
    
    try:
        df_resumo.to_excel(nome_arquivo, index=False, engine='openpyxl')
        print(f"Relat√≥rio de resumo salvo em: {nome_arquivo}")
    except Exception as e:
        print(f"ERRO ao salvar o arquivo de resumo '{nome_arquivo}': {e}")


def salvar_excel(df, nome_arquivo, colunas_ordem):
    """Fun√ß√£o auxiliar para salvar DataFrames em Excel com formata√ß√£o."""
    if df.empty:
        print(f"\nNenhum item para salvar em '{nome_arquivo}'.")
        return

    df_copy = df.copy()
    df_copy['Prefixo'] = df_copy['Arquivo'].str[:3].str.upper()
    df_copy['Classifica√ß√£o'] = df_copy['Arquivo'].apply(classificar_arquivo)
    
    # Ordenar para melhor visualiza√ß√£o (sem convers√£o num√©rica)
    if "Categoria" in df_copy.columns:
        df_copy = df_copy.sort_values(by=['Classifica√ß√£o', 'Arquivo', 'Localizador'])
    else:
        df_copy = df_copy.sort_values(by=['Arquivo', 'Localizador'])

    colunas_presentes = df_copy.columns.tolist()
    colunas_finais = [col for col in colunas_ordem if col in colunas_presentes]
    df_final = df_copy[colunas_finais]

    try:
        df_final.to_excel(nome_arquivo, index=False, engine='openpyxl')
        print(f"Relat√≥rio salvo em: {nome_arquivo}")
    except Exception as e:
        print(f"ERRO ao salvar o arquivo '{nome_arquivo}': {e}")


def main():
    print("--- INICIANDO AN√ÅLISE DE IMPACTO DE CNPJ ALFANUM√âRICO (v5 - com tipo de termo) ---")

    termos_busca = carregar_termos_busca(ARQUIVO_TERMOS)
    if not termos_busca:
        return

    print(f"Analisando o arquivo: {ARQUIVO_ENTRADA}")
    if not os.path.exists(ARQUIVO_ENTRADA):
        print(f"ERRO: Arquivo de entrada n√£o encontrado em '{ARQUIVO_ENTRADA}'")
        return

    # Etapa 1: Ler o arquivo de entrada e agrupar por linha de c√≥digo √∫nica
    linhas_unicas = {}
    linhas_ignoradas = []
    print("Etapa 1: Lendo, buscando termos e agrupando linhas de c√≥digo √∫nicas...")
    with open(ARQUIVO_ENTRADA, 'r', encoding='utf-8', errors='ignore') as f_in:
        for linha_bruta in f_in:
            linha_strip = linha_bruta.strip()
            if "Searching for" in linha_strip or not linha_strip:
                continue

            arquivo, num_linha, codigo_original = extrair_info_linha(linha_strip)
            if not arquivo:
                linhas_ignoradas.append(f"Formato Inv√°lido: {linha_strip}")
                continue

            codigo_para_analise = codigo_original # Analisar a linha inteira
            
            termos_encontrados_na_linha = {} # {termo: tipo}
            for termo, tipo in termos_busca.items():
                regex = ''
                # Sub-rotinas s√£o buscadas como palavras completas para evitar falsos positivos
                if tipo == 'sub-rotina':
                    regex = r'\b' + re.escape(termo) + r'\b'
                # Vari√°veis e texto-livre podem ser parte de outra string
                elif tipo in ['variavel', 'texto-livre']:
                    regex = re.escape(termo)
                
                if regex and re.search(regex, codigo_para_analise, re.IGNORECASE):
                    termos_encontrados_na_linha[termo] = tipo
            
            if not termos_encontrados_na_linha:
                linhas_ignoradas.append(f"Nenhum Termo Encontrado: {linha_strip}")
                continue

            chave = (arquivo, num_linha)
            if chave not in linhas_unicas:
                linhas_unicas[chave] = {'code': codigo_original, 'terms': {}}
            
            linhas_unicas[chave]['terms'].update(termos_encontrados_na_linha)

    print(f"  - {len(linhas_unicas)} linhas de c√≥digo √∫nicas encontradas para an√°lise.")
    print(f"  - {len(linhas_ignoradas)} linhas ignoradas (formato inv√°lido ou sem termos).")

    # Salvar o relat√≥rio de linhas ignoradas
    if linhas_ignoradas:
        try:
            with open('analise_linhas_ignoradas.txt', 'w', encoding='utf-8') as f:
                for linha in sorted(linhas_ignoradas):
                    f.write(f"{linha}\n")
            print("Arquivo com linhas ignoradas salvo em: analise_linhas_ignoradas.txt")
        except Exception as e:
            print(f"ERRO ao salvar o arquivo de linhas ignoradas: {e}")

    # Etapa 2: Classificar cada linha de c√≥digo √∫nica
    print("Etapa 2: Classificando cada linha...")
    resultados_ajustes = []
    resultados_descartados = []

    for (arquivo, num_linha), data in linhas_unicas.items():
        codigo_original = data['code']
        termos_encontrados = data['terms'] # √â um dict {termo: tipo}
        codigo_para_analise = codigo_original # Usar a linha inteira para an√°lise
        
        # Constr√≥i a string de vari√°veis para o relat√≥rio
        variaveis_str = ", ".join(sorted(termos_encontrados.keys()))
        foi_classificada = False

        # --- L√ìGICA DE CLASSIFICA√á√ÉO REESTRUTURADA ---
        
        # Etapa 1: Descartar coment√°rios (prioridade m√°xima e sem exce√ß√µes)
        if re.match(r"^\s*(;+|//)", codigo_para_analise):
            resultados_descartados.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Regra de Descarte": "Coment√°rio", "C√≥digo": codigo_original
            })
            continue

        # Etapa 2: Descartar rotinas n√£o oficiais ou scripts
        classificacao_arquivo = classificar_arquivo(arquivo)
        if classificacao_arquivo in ['N√£o Oficiais', 'Scripts']:
            motivo = "Rotina de Script" if classificacao_arquivo == 'Scripts' else "Rotina N√£o Oficial"
            resultados_descartados.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Regra de Descarte": motivo, "C√≥digo": codigo_original
            })
            continue
            
        # Etapa 3: Se n√£o foi descartada, aplicar outras regras e classifica√ß√µes
        
        # Separa os termos encontrados por tipo para aplicar l√≥gicas distintas
        vars_na_linha = [t for t, tipo in termos_encontrados.items() if tipo == 'variavel']
        subs_na_linha = [t for t, tipo in termos_encontrados.items() if tipo == 'sub-rotina']

        # 3.1: L√≥gica para Sub-rotinas
        if subs_na_linha:
            resultados_ajustes.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Categoria": "CHAMADA_SUBROTINA", "Padr√£o": "Chamada de Sub-rotina",
                "Justificativa": f"Chamada √†(s) sub-rotina(s): {', '.join(sorted(subs_na_linha))}.", 
                "C√≥digo": codigo_original
            })
            foi_classificada = True
        
        # 3.2: L√≥gica para Vari√°veis (se houver e n√£o tiver sido classificada como sub-rotina)
        if vars_na_linha and not foi_classificada:
            vars_regex_linha = r'\b(' + '|'.join(re.escape(v) for v in vars_na_linha) + r')\b'
            
            # Aplicar regras de DESCARTE restantes
            for motivo, regex in REGRAS_DESCARTE_CONFIANCA:
                if motivo == "Coment√°rio": continue # J√° foi tratado
                
                regex_com_vars = regex.replace('VARIAVEL', vars_regex_linha)
                if re.search(regex_com_vars, codigo_para_analise, re.IGNORECASE):
                    resultados_descartados.append({
                        "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                        "Regra de Descarte": motivo, "C√≥digo": codigo_original
                    })
                    foi_classificada = True
                    break
            if foi_classificada: continue

            # Aplicar regras de AJUSTE CR√çTICO
            for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
                regex_com_vars = regex.replace('VARIAVEL', vars_regex_linha)
                if re.search(regex_com_vars, codigo_para_analise, re.IGNORECASE):
                    resultados_ajustes.append({
                        "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                        "Categoria": categoria, "Padr√£o": nome, "Justificativa": just, "C√≥digo": codigo_original
                    })
                    foi_classificada = True
                    break
            if foi_classificada: continue

        # Etapa 4: Padr√£o final -> Revis√£o Manual
        if not foi_classificada:
            justificativa = "Termo de texto-livre encontrado." if not vars_na_linha else "N√£o corresponde a nenhum padr√£o de ajuste ou descarte conhecido."
            resultados_ajustes.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Categoria": "REVISAO_MANUAL", "Padr√£o": "Revis√£o Manual Necess√°ria", 
                "Justificativa": justificativa,
                "C√≥digo": codigo_original
            })

    print(f"\nAn√°lise conclu√≠da.")
    print(f"  - Total de linhas √∫nicas analisadas: {len(linhas_unicas)}")
    print(f"  - Pontos de ajuste cr√≠tico identificados: {len(resultados_ajustes)}")
    print(f"  - Itens descartados: {len(resultados_descartados)}")

    # Gerar Relat√≥rio de Ajustes Cr√≠ticos
    if resultados_ajustes:
        df_ajustes = pd.DataFrame(resultados_ajustes)
        df_ajustes['Tipo Programa'] = df_ajustes['Arquivo'].str.split('.').str[-1]
        df_ajustes['Prefixo'] = df_ajustes['Arquivo'].str[:3].str.upper()
        df_ajustes['Classifica√ß√£o'] = df_ajustes['Arquivo'].apply(classificar_arquivo)
        colunas_ajustes = [
            "Arquivo", "Tipo Programa", "Prefixo", "Classifica√ß√£o", "Linha", "Vari√°vel",
            "Categoria", "Padr√£o", "Justificativa", "C√≥digo"
        ]
        df_ajustes.rename(columns={'Linha': 'Localizador'}, inplace=True)
        colunas_ajustes[4] = 'Localizador'
        salvar_excel(df_ajustes, ARQUIVO_SAIDA_AJUSTES, colunas_ajustes)
        gerar_relatorio_precificacao_realista(df_ajustes)
        gerar_relatorio_resumo(df_ajustes, ARQUIVO_SAIDA_RESUMO)

    # Gerar Relat√≥rio de Descartes
    if resultados_descartados:
        df_descartados = pd.DataFrame(resultados_descartados)
        df_descartados['Tipo Programa'] = df_descartados['Arquivo'].str.split('.').str[-1]
        df_descartados['Prefixo'] = df_descartados['Arquivo'].str[:3].str.upper()
        df_descartados['Classifica√ß√£o'] = df_descartados['Arquivo'].apply(classificar_arquivo)
        colunas_descartes = [
            "Arquivo", "Tipo Programa", "Prefixo", "Classifica√ß√£o", "Linha",
            "Vari√°vel", "Regra de Descarte", "C√≥digo"
        ]
        df_descartados.rename(columns={'Linha': 'Localizador'}, inplace=True)
        colunas_descartes[4] = 'Localizador'
        salvar_excel(df_descartados, ARQUIVO_SAIDA_DESCARTES, colunas_descartes)
        df_descartes_oficiais = df_descartados[df_descartados['Classifica√ß√£o'] == 'Oficiais'].copy()
        salvar_excel(df_descartes_oficiais, ARQUIVO_SAIDA_DESCARTES_OFICIAIS, colunas_descartes)

        # Salvar o relat√≥rio espec√≠fico de descarte por extra√ß√£o simples
        df_extracao_simples = df_descartados[df_descartados['Regra de Descarte'] == 'Extra√ß√£o Simples de Substring'].copy()
        salvar_excel(df_extracao_simples, ARQUIVO_SAIDA_DESCARTES_EXTRACAO, colunas_descartes)

if __name__ == "__main__":
    main()