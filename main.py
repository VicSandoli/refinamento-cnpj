import re
import csv
import os
import pandas as pd

# --- CONFIGURA√á√ÉO ---

# 1. Coloque aqui o caminho do seu arquivo de entrada
ARQUIVO_ENTRADA = 'CNPJresults_findStudio 3.txt'

# 2. Nomes dos arquivos de sa√≠da que ser√£o gerados
ARQUIVO_SAIDA_IMPACTO = 'analise_impacto_cnpj_refinada.xlsx'
ARQUIVO_SAIDA_DESCARTES = 'analise_descartes.xlsx'
ARQUIVO_SAIDA_NAO_CLASSIFICADOS = 'analise_sem_classificacao.xlsx'
ARQUIVO_SAIDA_PRECIFICACAO = 'analise_precificacao_proposta.xlsx'

# 3. Arquivo com as vari√°veis a serem analisadas
ARQUIVO_VARIAVEIS = 'CNPJ 1.csv'

# --- CATEGORIAS PARA PRECIFICA√á√ÉO REALISTA ---

# Premissa: Solu√ß√£o centralizada ser√° implementada para tratar CNPJ alfanum√©rico
# Estimativas por CATEGORIA (n√£o por ponto individual)
CATEGORIAS_AJUSTE = {
    "VALIDACAO_ENTRADA": {
        "nome": "Valida√ß√£o e Entrada de Dados",
        "descricao": "Pontos que validam entrada de CNPJ - ser√£o ajustados para usar fun√ß√£o central",
        "esforco_base": 56,  # horas totais para a categoria (+40%)
        "esforco_testes": 22,  # horas de testes QA (+40%)
        "observacao": "Implementa√ß√£o de fun√ß√£o central + ajustes pontuais + valida√ß√µes espec√≠ficas"
    },
    "FORMATACAO_EXIBICAO": {
        "nome": "Formata√ß√£o e Exibi√ß√£o",
        "descricao": "Pontos que formatam CNPJ para exibi√ß√£o - usar√£o fun√ß√£o central de formata√ß√£o",
        "esforco_base": 30,  # horas totais (+25%)
        "esforco_testes": 10,  # horas de testes QA (+25%)
        "observacao": "Substitui√ß√£o por chamadas √† fun√ß√£o central + ajustes de layout"
    },
    "LOGICA_NEGOCIO": {
        "nome": "L√≥gica de Neg√≥cio Espec√≠fica",
        "descricao": "Pontos com l√≥gica espec√≠fica que precisam revis√£o manual",
        "esforco_base": 120, # horas totais (+50%)
        "esforco_testes": 48,  # horas de testes QA (+50%)
        "observacao": "An√°lise caso a caso + reengenharia + adapta√ß√£o + testes espec√≠ficos"
    },
    "INTEGRACAO_EXTERNA": {
        "nome": "Integra√ß√µes Externas",
        "descricao": "Interfaces com sistemas externos - an√°lise de compatibilidade",
        "esforco_base": 50,  # horas totais (+56%)
        "esforco_testes": 40,  # horas de testes QA (+67% - mais testes por ser integra√ß√£o)
        "observacao": "Verifica√ß√£o de compatibilidade + adapta√ß√£o + testes de integra√ß√£o"
    },
    "ESTRUTURA_DADOS": {
        "nome": "Estrutura de Dados",
        "descricao": "Ajustes em banco de dados, √≠ndices e consultas",
        "esforco_base": 24,  # horas totais (+50%)
        "esforco_testes": 12,  # horas de testes QA (+50%)
        "observacao": "Revis√£o de tipos de dados + √≠ndices + performance + migra√ß√£o"
    }
}

# --- REGRAS SIMPLIFICADAS PARA CATEGORIZA√á√ÉO ---

# REGRAS GLOBAIS: Verificadas em TODAS as linhas
REGRAS_GLOBAIS_CATEGORIAS = [
    (
        "M√°scara Num√©rica Expl√≠cita",
        r"\?\d*N",
        "VALIDACAO_ENTRADA",
        "M√°scara que for√ßa entrada num√©rica - precisa aceitar alfanum√©rico."
    ),
]

# REGRAS VINCULADAS: Verificadas apenas em linhas que cont√™m uma vari√°vel alvo
REGRAS_VINCULADAS_CATEGORIAS = [
    # --- VALIDA√á√ÉO E ENTRADA ---
    (
        "Valida√ß√£o de Entrada",
        r"(if.*\bVARIAVEL\b.*[=<>]\s*\d+|\$L\(.*\bVARIAVEL\b.*\)\s*[=<>]\s*1[14])",
        "VALIDACAO_ENTRADA",
        "Valida√ß√£o que assume formato/comprimento espec√≠fico - usar fun√ß√£o central."
    ),
    (
        "Convers√£o Num√©rica",
        r"(\$NUMBER\s*\(\s*\bVARIAVEL\b|if.*\bVARIAVEL\b.*[+\-*/])",
        "VALIDACAO_ENTRADA",
        "Convers√£o para n√∫mero ou opera√ß√£o aritm√©tica - usar fun√ß√£o central."
    ),
    
    # --- FORMATA√á√ÉO E EXIBI√á√ÉO ---
    (
        "Formata√ß√£o Manual",
        r'(\bVARIAVEL\b\s*_\s*"[\./-]"|Write.*\bVARIAVEL\b)',
        "FORMATACAO_EXIBICAO",
        "Formata√ß√£o manual para exibi√ß√£o - usar fun√ß√£o central de formata√ß√£o."
    ),
    
    # --- L√ìGICA DE NEG√ìCIO ---
    (
        "Extra√ß√£o de CNPJ Raiz",
        r"(\$E|\$EXTRACT)\s*\(\s*\bVARIAVEL\b\s*,\s*1\s*,\s*(8|12)\s*\)",
        "LOGICA_NEGOCIO",
        "Extra√ß√£o de raiz com comprimento fixo - revisar l√≥gica para alfanum√©rico."
    ),
    (
        "Manipula√ß√£o Espec√≠fica",
        r"(\$E|\$EXTRACT)\s*\(\s*\bVARIAVEL\b",
        "LOGICA_NEGOCIO",
        "Manipula√ß√£o espec√≠fica de substring - verificar se permanece v√°lida."
    ),
    
    # --- INTEGRA√á√ÉO EXTERNA ---
    (
        "Interface Externa",
        r"(HTTP|REST|SOAP|XML|JSON|EXPORT|IMPORT|FILE).*\bVARIAVEL\b|\bVARIAVEL\b.*(HTTP|REST|SOAP|XML|JSON|EXPORT|IMPORT|FILE)",
        "INTEGRACAO_EXTERNA",
        "Interface externa - verificar se destino suporta CNPJ alfanum√©rico."
    ),
    
    # --- ESTRUTURA DE DADOS ---
    (
        "Opera√ß√£o de Banco",
        r"(SELECT|INSERT|UPDATE|DELETE|ORDER\s+BY|GROUP\s+BY|WHERE).*\bVARIAVEL\b",
        "ESTRUTURA_DADOS",
        "Opera√ß√£o de banco - verificar tipos de dados e performance."
    ),
]

def carregar_variaveis_alvo(caminho_csv):
    """
    Carrega dinamicamente as vari√°veis de um arquivo CSV.
    Assume que o delimitador √© ';' e as vari√°veis est√£o na 5¬™ coluna (√≠ndice 4).
    Filtra para manter apenas nomes de vari√°veis v√°lidos.
    """
    if not os.path.exists(caminho_csv):
        print(f"ERRO: Arquivo de vari√°veis '{caminho_csv}' n√£o encontrado.")
        return []

    variaveis = set()
    with open(caminho_csv, 'r', encoding='utf-8', errors='ignore') as f:
        reader = csv.reader(f, delimiter=';')
        next(reader, None)  # Pula o cabe√ßalho
        for row in reader:
            if len(row) > 4 and row[4].strip():
                var = row[4].strip()
                # Filtro simples para nomes de vari√°veis (come√ßa com letra, pode ter n√∫meros/underline)
                if re.match(r'^[a-zA-Z][a-zA-Z0-9_]*$', var):
                    variaveis.add(var)
    
    print(f"{len(variaveis)} vari√°veis carregadas de {caminho_csv}")
    return list(variaveis)


def extrair_info_linha(linha):
    """Extrai o nome do arquivo, n√∫mero da linha e o c√≥digo da linha de entrada."""
    match = re.match(r"^(.*?)\((\d+)\):\s*(.*)", linha)
    if match:
        return match.groups()
    return None, None, None

# --- FUN√á√ïES DE AN√ÅLISE REESTRUTURADAS ---

def analisar_regras_globais(codigo):
    """Aplica as regras globais de categoriza√ß√£o ao c√≥digo."""
    for nome, regex, categoria, just in REGRAS_GLOBAIS_CATEGORIAS:
        if re.search(regex, codigo, re.IGNORECASE):
            return nome, categoria, just, regex
    return None

def analisar_regras_vinculadas(codigo, var_alvo):
    """Aplica as regras vinculadas de categoriza√ß√£o a uma vari√°vel espec√≠fica."""
    for nome, regex, categoria, just in REGRAS_VINCULADAS_CATEGORIAS:
        regex_var = regex.replace('VARIAVEL', var_alvo)
        if re.search(regex_var, codigo, re.IGNORECASE):
            return nome, categoria, just
    return None

def gerar_relatorio_precificacao_realista(df_impacto):
    """Gera relat√≥rio de precifica√ß√£o baseado em categorias de ajuste (n√£o por ponto)."""
    if df_impacto.empty:
        print("\nNenhum dado para relat√≥rio de precifica√ß√£o.")
        return
    
    # Adicionar colunas auxiliares
    df_impacto['Classifica√ß√£o'] = df_impacto['Arquivo'].apply(classificar_arquivo)
    
    # Filtrar apenas rotinas oficiais
    df_oficiais = df_impacto[df_impacto['Classifica√ß√£o'] == 'Oficiais'].copy()
    
    print(f"üìä An√°lise focada em ROTINAS OFICIAIS: {len(df_oficiais)} pontos de {len(df_impacto)} totais")
    
    if df_oficiais.empty:
        print("Nenhuma rotina oficial encontrada.")
        return
    
    # Contar pontos por categoria
    contagem_categorias = df_oficiais['Categoria'].value_counts()
    
    # 1. Summary por Categoria de Ajuste
    summary_categorias = []
    total_dev = 0
    total_testes = 0
    
    for categoria, config in CATEGORIAS_AJUSTE.items():
        pontos_categoria = contagem_categorias.get(categoria, 0)
        
        if pontos_categoria > 0:
            # Esfor√ßo base + proporcional ao n√∫mero de pontos (m√°ximo 50% extra)
            fator_pontos = min(1 + (pontos_categoria - 1) * 0.1, 1.5)  # Max 50% extra
            esforco_dev = round(config["esforco_base"] * fator_pontos)
            esforco_testes = round(config["esforco_testes"] * fator_pontos)
            
            total_dev += esforco_dev
            total_testes += esforco_testes
            
            summary_categorias.append({
                "Categoria": config["nome"],
                "Pontos Identificados": str(pontos_categoria),  # Converter para string
                "Esfor√ßo Dev (h)": esforco_dev,
                "Esfor√ßo Testes (h)": esforco_testes,
                "Total (h)": esforco_dev + esforco_testes,
                "Observa√ß√£o": config["observacao"],
                "Descri√ß√£o": config["descricao"]
            })
    
    # 2. Esfor√ßo da Solu√ß√£o Central
    esforco_central = {
        "Categoria": "Solu√ß√£o Central - Fun√ß√µes Base",
        "Pontos Identificados": "Base",  # String consistente
        "Esfor√ßo Dev (h)": 120,  # Desenvolvimento das fun√ß√µes centrais
        "Esfor√ßo Testes (h)": 40,   # Testes unit√°rios das fun√ß√µes centrais
        "Total (h)": 160,
        "Observa√ß√£o": "Fun√ß√µes de valida√ß√£o, formata√ß√£o e utilit√°rios CNPJ alfanum√©rico",
        "Descri√ß√£o": "Desenvolvimento das fun√ß√µes centralizadas que ser√£o usadas em todo o sistema"
    }
    
    # Adicionar solu√ß√£o central no in√≠cio
    summary_categorias.insert(0, esforco_central)
    total_dev += 120
    total_testes += 40
    
    # 3. Summary Executivo
    total_geral = total_dev + total_testes
    
    summary_executivo = [{
        "M√©trica": "Esfor√ßo Desenvolvimento",
        "Valor": f"{total_dev}h",
        "Observa√ß√£o": "Desenvolvimento + adapta√ß√µes pontuais"
    }, {
        "M√©trica": "Esfor√ßo Testes QA", 
        "Valor": f"{total_testes}h",
        "Observa√ß√£o": "Testes unit√°rios + integra√ß√£o + regress√£o"
    }, {
        "M√©trica": "Total Estimado",
        "Valor": f"{total_geral}h",
        "Observa√ß√£o": "Estimativa realista considerando solu√ß√£o centralizada"
    }, {
        "M√©trica": "Pontos Oficiais Analisados",
        "Valor": str(len(df_oficiais)),  # Converter para string
        "Observa√ß√£o": "Apenas rotinas oficiais consideradas"
    }, {
        "M√©trica": "Estimativa com Buffer 20%",
        "Valor": f"{round(total_geral * 1.2)}h",
        "Observa√ß√£o": "Margem para imprevistos (mais conservadora)"
    }]
    
    # 4. Distribui√ß√£o por M√≥dulo (apenas oficiais)
    df_oficiais['Prefixo'] = df_oficiais['Arquivo'].str[:3].str.upper()
    summary_modulos = []
    
    for prefixo in sorted(df_oficiais['Prefixo'].unique()):
        dados_modulo = df_oficiais[df_oficiais['Prefixo'] == prefixo]
        categorias_modulo = dados_modulo['Categoria'].value_counts()
        
        summary_modulos.append({
            "Prefixo M√≥dulo": prefixo,
            "Pontos Totais": str(len(dados_modulo)),  # Converter para string
            "Categorias": ', '.join([f"{cat}({qtd})" for cat, qtd in categorias_modulo.items()]),
            "% dos Pontos": round((len(dados_modulo) / len(df_oficiais)) * 100, 1)
        })
    
    # Salvar relat√≥rios
    try:
        with pd.ExcelWriter(ARQUIVO_SAIDA_PRECIFICACAO, engine='openpyxl') as writer:
            # Aba 1: Summary Executivo
            pd.DataFrame(summary_executivo).to_excel(
                writer, sheet_name='1_Summary_Executivo', index=False
            )
            
            # Aba 2: Por Categoria de Ajuste
            pd.DataFrame(summary_categorias).to_excel(
                writer, sheet_name='2_Por_Categoria_Ajuste', index=False
            )
            
            # Aba 3: Por M√≥dulo
            pd.DataFrame(summary_modulos).to_excel(
                writer, sheet_name='3_Por_Modulo_Oficiais', index=False
            )
            
            # Aba 4: Detalhamento de pontos cr√≠ticos  
            if len(df_oficiais) > 0:
                pontos_criticos = df_oficiais.head(20)[
                    ['Arquivo', 'Linha', 'Categoria', 'Padr√£o', 'Justificativa', 'C√≥digo']
                ]
            else:
                pontos_criticos = pd.DataFrame()
            pontos_criticos.to_excel(
                writer, sheet_name='4_Pontos_Criticos', index=False
            )
            
        print(f"Relat√≥rio de precifica√ß√£o realista salvo em: {ARQUIVO_SAIDA_PRECIFICACAO}")
        print(f"üìä RESUMO EXECUTIVO:")
        print(f"   ‚Ä¢ Pontos oficiais analisados: {len(df_oficiais)}")
        print(f"   ‚Ä¢ Desenvolvimento: {total_dev}h")
        print(f"   ‚Ä¢ Testes QA: {total_testes}h") 
        print(f"   ‚Ä¢ Total: {total_geral}h")
        print(f"   ‚Ä¢ Com buffer 20%: {round(total_geral * 1.2)}h")
        
    except Exception as e:
        print(f"ERRO ao salvar relat√≥rio de precifica√ß√£o: {e}")

# REGRAS DE DESCARTE: mantidas do c√≥digo original
REGRAS_VINCULADAS_DESCARTE = [
    # Descarte de strings literais (maior prioridade)
    (r'^\s*(S|Set)\s+\w+\s*=\s*".*\bVARIAVEL\b.*"', "Atribui√ß√£o de String Literal"),
    (r'^\s*W(rite)?\s*!?,?\s*".*\bVARIAVEL\b.*"', "Escrita de String Literal"),
    # Coment√°rios
    (r"^\s*;", "Coment√°rio"),
    (r"\brem\b", "Coment√°rio 'rem'"),
    (r"^\s*//", "Coment√°rio '//'"),
    (r"^\s*#;", "Coment√°rio '#;'"),
    # Outras regras de descarte
    (r",\s*\w+\s*=\s*\bVARIAVEL\b", "Atribui√ß√£o Simples (M√∫ltiplos Comandos)"),
    (r"^\s*Do\s+.*\^.*\bVARIAVEL\b", "Chamada de Rotina (Do)"),
    (r"\$O\s*\(.*\bVARIAVEL\b", "Uso em $ORDER"),
    (r"^\s*Write\s+.*\bVARIAVEL\b", "Escrita simples (Write)"),
    (r"^\s*(S|Set)\s+\w+\s*=\s*\bVARIAVEL\b\s*($|;)", "Atribui√ß√£o Simples"),
    (r"\$\$\$PARAMETROS\s*\(.*\bVARIAVEL\b", "Uso em macro $$$PARAMETROS"),
    (r"'\$D\(.*\bVARIAVEL\b.*\)", "Verifica√ß√£o de exist√™ncia em Global ($D)"),
    (r"New\s+.*\bVARIAVEL\b", "Declara√ß√£o New"),
    (r'S\s*\(?.*\bVARIAVEL\b.*\)?\s*=\s*""', "Inicializa√ß√£o para vazio"),
    (r'Set\s+\bVARIAVEL\b\s*=\s*""', "Set para vazio"),
    (r'if\s+\bVARIAVEL\b\s*=\s*""', "Compara√ß√£o com vazio"),
    (r'if\s+\bVARIAVEL\b\s*\'\s*=\s*""', "Compara√ß√£o com vazio"),
    (r"if\s+\$G\(\bVARIAVEL\b", "Verifica√ß√£o com $GET"),
    (r'G:\bVARIAVEL\b\?1""', "GOTO se nulo"),
    (r"Write\s+.*/CAMPO\s*\(" , "Escrita em campo de tela"),
    (r"Set\s+.*\s*=\s*##class\(", "Chamada de m√©todo de classe"),
    (r"\.cpfcnpj\s*=", "Atribui√ß√£o a propriedade de objeto"),
]



def checar_descarte_vinculado(codigo, var_alvo):
    """Verifica se a linha deve ser ignorada com base nas regras de descarte vinculadas."""
    for regex, motivo in REGRAS_VINCULADAS_DESCARTE:
        regex_var = regex.replace('VARIAVEL', var_alvo)
        if re.search(regex_var, codigo, re.IGNORECASE):
            return motivo
    return None

def classificar_arquivo(nome_arquivo):
    """Adiciona classifica√ß√£o 'Oficiais', 'Scripts' ou 'N√£o Oficiais'."""
    prefixos_oficiais = [
        'dd', 'gap', 'i', 'audit', 'autobasi', 'basico', 'br', 'cbpi', 'csp',
        'estoque', 'faturamento', 'fiscal', 'frete', 'gem', 'ipi', 'ipp',
        'mnemonic', 'precos', 'sistema', 'supervisao', 'tropical', 'tti'
    ]
    nome_arquivo_lower = nome_arquivo.lower()
    if nome_arquivo_lower.startswith('aba'):
        return 'Scripts'
    if any(nome_arquivo_lower.startswith(p) for p in prefixos_oficiais):
        return 'Oficiais'
    return 'N√£o Oficiais'

def main():
    print("--- INICIANDO AN√ÅLISE DE IMPACTO DE CNPJ ALFANUM√âRICO (v2) ---")
    
    VARIAVEIS_ALVO = carregar_variaveis_alvo(ARQUIVO_VARIAVEIS)
    if not VARIAVEIS_ALVO:
        print("Nenhuma vari√°vel alvo para analisar. Encerrando.")
        return
        
    print(f"Analisando o arquivo: {ARQUIVO_ENTRADA}")
    if not os.path.exists(ARQUIVO_ENTRADA):
        print(f"ERRO: Arquivo de entrada n√£o encontrado em '{ARQUIVO_ENTRADA}'")
        return

    variaveis_regex = r"\b(" + "|".join(re.escape(var) for var in VARIAVEIS_ALVO) + r")\b"

    resultados_impacto = []
    resultados_descartados = []
    resultados_sem_classificacao = []
    
    linhas_analisadas = 0
    with open(ARQUIVO_ENTRADA, 'r', encoding='utf-8', errors='ignore') as f_in:
        for linha_bruta in f_in:
            linhas_analisadas += 1
            if "Searching for" in linha_bruta or not linha_bruta.strip():
                continue

            arquivo, num_linha, codigo_original = extrair_info_linha(linha_bruta.strip())
            if not arquivo:
                continue

            # PRE-PROCESSAMENTO: remove coment√°rios inline para an√°lise mais precisa
            codigo_para_analise = re.split(r'\s*//', codigo_original)[0].strip()

            # Otimiza√ß√£o: Descartar rotinas n√£o oficiais no in√≠cio
            if classificar_arquivo(arquivo) == 'N√£o Oficiais':
                match_var_descarte = re.search(variaveis_regex, codigo_para_analise, re.IGNORECASE)
                var_encontrada_descarte = match_var_descarte.group(0) if match_var_descarte else "N/A"
                resultados_descartados.append({
                    "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": var_encontrada_descarte.upper(),
                    "Regra de Descarte": "Rotina N√£o Oficial", "C√≥digo": codigo_original
                })
                continue

            foi_classificada = False

            # 1. An√°lise de Regras Globais (maior prioridade)
            resultado_global = analisar_regras_globais(codigo_para_analise)
            if resultado_global:
                regra, categoria, just, padrao = resultado_global
                resultados_impacto.append({
                    "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": f"Padr√£o Global: {padrao}",
                    "Categoria": categoria, "Padr√£o": regra, "Justificativa": just,
                    "C√≥digo": codigo_original
                })
                foi_classificada = True

            # 2. An√°lise Vinculada a Vari√°vel (se n√£o classificada globalmente)
            if not foi_classificada:
                match_var = re.search(variaveis_regex, codigo_para_analise, re.IGNORECASE)
                if match_var:
                    var_encontrada = match_var.group(0)

                    # 2a. Checar Categoriza√ß√£o Vinculada
                    resultado_categoria = analisar_regras_vinculadas(codigo_para_analise, var_encontrada)
                    if resultado_categoria:
                        regra, categoria, just = resultado_categoria
                        resultados_impacto.append({
                            "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": var_encontrada.upper(),
                            "Categoria": categoria, "Padr√£o": regra, "Justificativa": just,
                            "C√≥digo": codigo_original
                        })
                        foi_classificada = True
                    else:
                        # 2b. Checar Descarte (apenas se n√£o houver categoriza√ß√£o)
                        motivo_descarte = checar_descarte_vinculado(codigo_para_analise, var_encontrada)
                        if motivo_descarte:
                            resultados_descartados.append({
                                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": var_encontrada.upper(),
                                "Regra de Descarte": motivo_descarte, "C√≥digo": codigo_original
                            })
                            foi_classificada = True


            # 3. Coletar itens n√£o classificados que cont√™m vari√°veis
            if not foi_classificada:
                 match_var = re.search(variaveis_regex, codigo_para_analise, re.IGNORECASE)
                 if match_var:
                    resultados_sem_classificacao.append({
                        "Arquivo": arquivo, "Linha": num_linha,
                        "Vari√°vel Encontrada": match_var.group(0).upper(),
                        "C√≥digo": codigo_original
                    })


    print(f"\nAn√°lise conclu√≠da.")
    print(f"Total de linhas lidas: {linhas_analisadas}")
    print(f"Pontos de impacto identificados: {len(resultados_impacto)}")
    print(f"Itens descartados: {len(resultados_descartados)}")
    print(f"Itens sem classifica√ß√£o: {len(resultados_sem_classificacao)}")

    # Fun√ß√£o auxiliar para salvar DataFrames
    def salvar_excel(df, nome_arquivo, colunas_ordem):
        if df.empty:
            print(f"\nNenhum item para salvar em '{nome_arquivo}'.")
            return
        
        df_copy = df.copy()
        df_copy['Prefixo'] = df_copy['Arquivo'].str[:3].str.upper()
        df_copy['Classifica√ß√£o'] = df_copy['Arquivo'].apply(classificar_arquivo)
        df_copy['LinhaInt'] = pd.to_numeric(df_copy['Linha'])
        
        # Ordena√ß√£o especial para o DataFrame de impacto
        if "Categoria" in df_copy.columns:
            # Ordena√ß√£o por prioridade de categoria
            ordem_categoria = {
                "VALIDACAO_ENTRADA": 0,
                "LOGICA_NEGOCIO": 1, 
                "INTEGRACAO_EXTERNA": 2,
                "ESTRUTURA_DADOS": 3,
                "FORMATACAO_EXIBICAO": 4
            }
            df_copy['OrdemCategoria'] = df_copy['Categoria'].map(ordem_categoria).fillna(99)
            df_copy = df_copy.sort_values(by=['OrdemCategoria', 'Arquivo', 'LinhaInt'], ascending=[True, True, True])
        else:
            df_copy = df_copy.sort_values(by=['Arquivo', 'LinhaInt'])

        # Garante que todas as colunas esperadas existam antes de reordenar
        colunas_presentes = df_copy.columns.tolist()
        colunas_finais = [col for col in colunas_ordem if col in colunas_presentes]
        
        df_final = df_copy[colunas_finais]

        try:
            df_final.to_excel(nome_arquivo, index=False, engine='openpyxl')
            print(f"Relat√≥rio salvo em: {nome_arquivo}")
        except Exception as e:
            print(f"ERRO ao salvar o arquivo '{nome_arquivo}': {e}")

    # Gerar Relat√≥rio de Impacto
    if resultados_impacto:
        df_impacto = pd.DataFrame(resultados_impacto)
        colunas_impacto = [
            "Arquivo", "Prefixo", "Classifica√ß√£o", "Linha", "Vari√°vel",
            "Categoria", "Padr√£o", "Justificativa", "C√≥digo"
        ]
        salvar_excel(df_impacto, ARQUIVO_SAIDA_IMPACTO, colunas_impacto)
        
        # Gerar Relat√≥rio de Precifica√ß√£o REALISTA (foco em rotinas oficiais)
        gerar_relatorio_precificacao_realista(df_impacto)

    # Gerar Relat√≥rio de Descartes
    if resultados_descartados:
        df_descartados = pd.DataFrame(resultados_descartados)
        colunas_descartes = [
            "Arquivo", "Prefixo", "Classifica√ß√£o", "Linha",
            "Vari√°vel", "Regra de Descarte", "C√≥digo"
        ]
        salvar_excel(df_descartados, ARQUIVO_SAIDA_DESCARTES, colunas_descartes)

    # Gerar Relat√≥rio de N√£o Classificados
    if resultados_sem_classificacao:
        df_nao_classificados = pd.DataFrame(resultados_sem_classificacao)
        colunas_nao_classificados = [
            "Arquivo", "Prefixo", "Classifica√ß√£o", "Linha",
            "Vari√°vel Encontrada", "C√≥digo"
        ]
        salvar_excel(df_nao_classificados, ARQUIVO_SAIDA_NAO_CLASSIFICADOS, colunas_nao_classificados)

if __name__ == "__main__":
    main()