import re
import csv
import os
import pandas as pd

# --- CONFIGURA√á√ÉO ---

# 1. Coloque aqui o caminho do seu arquivo de entrada
ARQUIVO_ENTRADA = 'CNPJresults_findStudio 3.txt'

# 2. Nomes dos arquivos de sa√≠da que ser√£o gerados
ARQUIVO_SAIDA_AJUSTES = 'analise_ajustes_criticos.xlsx'
ARQUIVO_SAIDA_DESCARTES = 'analise_descartes.xlsx'
ARQUIVO_SAIDA_DESCARTES_OFICIAIS = 'analise_descartes_oficiais.xlsx'
ARQUIVO_SAIDA_PRECIFICACAO = 'analise_precificacao_proposta.xlsx'

# 3. Arquivo com as vari√°veis a serem analisadas
ARQUIVO_VARIAVEIS = 'CNPJ 1.csv'

# --- CATEGORIAS PARA PRECIFICA√á√ÉO REALISTA ---
# Mantidas para gerar a estimativa de esfor√ßo final.
CATEGORIAS_AJUSTE = {
    "VALIDACAO_ENTRADA": {
        "nome": "Valida√ß√£o e Entrada de Dados",
        "descricao": "Pontos que validam entrada de CNPJ - ser√£o ajustados para usar fun√ß√£o central",
        "esforco_base": 56, "esforco_testes": 22,
        "observacao": "Implementa√ß√£o de fun√ß√£o central + ajustes pontuais"
    },
    "FORMATACAO_EXIBICAO": {
        "nome": "Formata√ß√£o e Exibi√ß√£o",
        "descricao": "Pontos que formatam CNPJ para exibi√ß√£o - usar√£o fun√ß√£o central",
        "esforco_base": 30, "esforco_testes": 10,
        "observacao": "Substitui√ß√£o por chamadas √† fun√ß√£o central"
    },
    "LOGICA_NEGOCIO": {
        "nome": "L√≥gica de Neg√≥cio Espec√≠fica",
        "descricao": "Pontos com l√≥gica espec√≠fica que precisam revis√£o manual",
        "esforco_base": 120, "esforco_testes": 48,
        "observacao": "An√°lise caso a caso, reengenharia e testes espec√≠ficos"
    },
    "INTEGRACAO_EXTERNA": {
        "nome": "Integra√ß√µes Externas",
        "descricao": "Interfaces com sistemas externos - an√°lise de compatibilidade",
        "esforco_base": 50, "esforco_testes": 40,
        "observacao": "Verifica√ß√£o de compatibilidade, adapta√ß√£o e testes de integra√ß√£o"
    },
    "ESTRUTURA_DADOS": {
        "nome": "Estrutura de Dados",
        "descricao": "Ajustes em banco de dados, √≠ndices e consultas",
        "esforco_base": 24, "esforco_testes": 12,
        "observacao": "Revis√£o de tipos de dados, √≠ndices, performance e migra√ß√£o"
    },
    "REVISAO_MANUAL": {
        "nome": "Revis√£o Manual Necess√°ria",
        "descricao": "Linhas que n√£o se encaixam em padr√µes conhecidos e exigem an√°lise",
        "esforco_base": 2, "esforco_testes": 1, # Custo por ponto
        "observacao": "An√°lise manual para determinar a categoria correta e o impacto"
    }
}

# --- REGRAS DE DESCARTE DE ALTA CONFIAN√áA ---
# Se uma linha corresponder a qualquer uma destas regras, ser√° descartada.
REGRAS_DESCARTE_CONFIANCA = [
    ("Coment√°rio", r"^\s*(;.*|//.*|#;.*|rem\s)"),
    ("String Literal", r'".*\bVARIAVEL\b.*"'),
    # Regra aprimorada para ser mais espec√≠fica e evitar descartar atribui√ß√µes que usam a vari√°vel
    ("Atribui√ß√£o Simples (de vari√°vel)", r"^\s*(S|Set)\s+\w+\s*=\s*\bVARIAVEL\b\s*($|;|,|!)"),
    # Regra aprimorada para permitir propriedades de objeto (ponto) e vari√°veis com '%'
    ("Atribui√ß√£o Simples (para vari√°vel)", r"^\s*(S|Set)\s+\bVARIAVEL\b\s*=\s*[%.\w]+\s*($|;|,|!)"),
    # Regra expandida para cobrir atribui√ß√µes em lista, como S ALT=0,CCLI=""
    ("Set para Vazio", r'^\s*(S|Set)\s+.*\bVARIAVEL\b\s*=\s*""|,\s*\bVARIAVEL\b\s*=\s*""'),
    # Nova regra, focada apenas na compara√ß√£o
    ("Compara√ß√£o com Vazio", r"if\s+'?\bVARIAVEL\b'?\s*=\s*"""),
    # Nova regra para compara√ß√£o com strings fixas
    ("Compara√ß√£o com String Fixa", r"^\s*(I|If)\s+'?\bVARIAVEL\b'?\s*=\s*"".*"""),
    ("Uso como Par√¢metro Simples", r"(\(|,)\s*\bVARIAVEL\b\s*(\)|,)"),
    ("Par√¢metro em Chamada de M√©todo/Fun√ß√£o", r"(##class\(|##super\(|\$\$\w+\^)\([^)]*\bVARIAVEL\b[^)]*\)"),
    ("Chamada de Rotina (Do)", r"^\s*Do\s+.*\^.*\bVARIAVEL\b"),
    ("Uso em $ORDER", r"\$O\s*\(.*\bVARIAVEL\b"),
    # Nova regra para o comando Kill
    ("Comando Kill", r"^\s*(K|Kill)\s+.*?\bVARIAVEL\b"),
    # Regra aprimorada para incluir a abrevia√ß√£o 'N' e ser mais precisa
    ("Declara√ß√£o New", r"^\s*(N|New)\s+.*?\bVARIAVEL\b"),
    ("Verifica√ß√£o de Exist√™ncia ($D, $G)", r"(if\s+\$G|\$D)\(.*\bVARIAVEL\b"),
]

# --- REGRAS PARA IDENTIFICAR AJUSTES CR√çTICOS ---
# Todas as linhas n√£o descartadas ser√£o testadas contra estas regras.
REGRAS_AJUSTE_CRITICO = [
    # --- VALIDA√á√ÉO E ENTRADA ---
    (
        "M√°scara Num√©rica Expl√≠cita", r"\?\d*N", "VALIDACAO_ENTRADA",
        "M√°scara que for√ßa entrada num√©rica - precisa aceitar alfanum√©rico."
    ),
    (
        "Valida√ß√£o de Comprimento", r"\$L(ENGTH)?\s*\(\s*\bVARIAVEL\b.*\)\s*[=<>]\s*(11|14)", "VALIDACAO_ENTRADA",
        "Valida√ß√£o de tamanho fixo - precisa ser flexibilizada."
    ),
    (
        "Convers√£o/Opera√ß√£o Num√©rica", r"(\$NUMBER|\$ZSTRIP)\s*\(\s*\bVARIAVEL\b|\bVARIAVEL\b\s*[\+\-\*\/]\s*\d+|\d+\s*[\+\-\*\/]\s*\bVARIAVEL\b", "VALIDACAO_ENTRADA",
        "Convers√£o para n√∫mero ou opera√ß√£o aritm√©tica - falhar√° com alfanum√©rico."
    ),
    # --- L√ìGICA DE NEG√ìCIO ---
    (
        "Padding com Soma", r"(1000000\d{6,}\s*\+\s*\bVARIAVEL\b|\bVARIAVEL\b\s*\+\s*1000000\d{6,})", "LOGICA_NEGOCIO",
        "T√©cnica de padding com soma para ordena√ß√£o/compara√ß√£o - incompat√≠vel com alfanum√©rico."
    ),
    (
        "Extra√ß√£o de Substring ($E, $EXTRACT)", r"(\$E|\$EXTRACT)\s*\(\s*\bVARIAVEL\b", "LOGICA_NEGOCIO",
        "Extra√ß√£o de partes do CNPJ (raiz, filial) - a l√≥gica pode precisar de revis√£o."
    ),
    (
        "Parsing com $PIECE", r"\$P(IECE)?\s*\(\s*\bVARIAVEL\b", "LOGICA_NEGOCIO",
        "Parsing da vari√°vel - pode ser afetado se o delimitador for um n√∫mero."
    ),
    # --- FORMATA√á√ÉO E EXIBI√á√ÉO ---
    (
        "Formata√ß√£o Manual para Exibi√ß√£o", r"(\bVARIAVEL\b\s*_\s*""[\.\/\-]"")|W(RITE)?\s+.*\bVARIAVEL\b", "FORMATACAO_EXIBICAO",
        "Formata√ß√£o manual para exibi√ß√£o - deve ser substitu√≠da por fun√ß√£o central."
    ),
    # --- INTEGRA√á√ÉO EXTERNA ---
    (
        "Uso em Contexto de Integra√ß√£o", r"(HTTP|REST|SOAP|XML|JSON|EXPORT|IMPORT|FTP|FILE).*\bVARIAVEL\b", "INTEGRACAO_EXTERNA",
        "Interface externa - verificar se o sistema destino suporta CNPJ alfanum√©rico."
    ),
    # --- ESTRUTURA DE DADOS ---
    (
        "Uso em Opera√ß√£o de Banco", r"&(SQL|sql)\(.*\bVARIAVEL\b.*\)|(SELECT|INSERT|UPDATE|DELETE|WHERE|ORDER\s+BY).*\bVARIAVEL\b", "ESTRUTURA_DADOS",
        "Opera√ß√£o de banco - verificar tipos de dados, √≠ndices e performance da consulta."
    ),
]


def carregar_variaveis_alvo(caminho_csv):
    """Carrega as vari√°veis de um arquivo CSV, filtrando nomes v√°lidos."""
    if not os.path.exists(caminho_csv):
        print(f"ERRO: Arquivo de vari√°veis '{caminho_csv}' n√£o encontrado.")
        return []
    try:
        df = pd.read_csv(caminho_csv, sep=';', usecols=['codigo'], encoding='utf-8', on_bad_lines='skip')
        df.dropna(subset=['codigo'], inplace=True)
        variaveis = df['codigo'].str.strip().unique()
        # Filtro para garantir que s√£o nomes de vari√°veis v√°lidos em Mumps
        filtro_regex = r'^[a-zA-Z%][a-zA-Z0-9]*$'
        variaveis_validas = {var for var in variaveis if isinstance(var, str) and re.match(filtro_regex, var)}
        print(f"{len(variaveis_validas)} vari√°veis √∫nicas e v√°lidas carregadas de {caminho_csv}")
        return list(variaveis_validas)
    except Exception as e:
        print(f"ERRO ao ler o arquivo de vari√°veis '{caminho_csv}': {e}")
        return []


def extrair_info_linha(linha):
    """Extrai o nome do arquivo, n√∫mero da linha e o c√≥digo da linha de entrada."""
    match = re.match(r"^(.*?)\((\d+)\):\s*(.*)", linha)
    if match:
        return match.groups()
    return None, None, None


def classificar_arquivo(nome_arquivo):
    """Adiciona classifica√ß√£o 'Oficiais', 'Scripts' ou 'N√£o Oficiais'."""
    prefixos_oficiais = [
        'dd', 'gap', 'i', 'audit', 'autobasi', 'basico', 'br', 'cbpi', 'csp',
        'estoque', 'faturamento', 'fiscal', 'frete', 'gem', 'ipi', 'ipp',
        'mnemonic', 'precos', 'sistema', 'supervisao', 'tropical', 'tti'
    ]
    nome_arquivo_lower = nome_arquivo.lower()
    if nome_arquivo_lower.startswith('aba'):
        return 'Scripts'
    if any(nome_arquivo_lower.startswith(p) for p in prefixos_oficiais):
        return 'Oficiais'
    return 'N√£o Oficiais'


def checar_descarte(codigo, var_alvo):
    """Verifica se a linha deve ser ignorada com base nas regras de descarte de alta confian√ßa."""
    for motivo, regex in REGRAS_DESCARTE_CONFIANCA:
        regex_var = regex.replace('VARIAVEL', re.escape(var_alvo))
        if re.search(regex_var, codigo, re.IGNORECASE):
            return motivo
    return None


def analisar_ponto_critico(codigo, var_alvo):
    """Aplica as regras de ajuste cr√≠tico e retorna a primeira correspond√™ncia."""
    # Primeiro, verifica regras que n√£o dependem da vari√°vel (globais)
    for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
        if 'VARIAVEL' not in regex:
            if re.search(regex, codigo, re.IGNORECASE):
                return nome, categoria, just, regex

    # Depois, verifica regras vinculadas √† vari√°vel
    for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
        if 'VARIAVEL' in regex:
            regex_var = regex.replace('VARIAVEL', re.escape(var_alvo))
            if re.search(regex_var, codigo, re.IGNORECASE):
                return nome, categoria, just, regex_var

    # Se nenhuma regra cr√≠tica corresponder, classifica para revis√£o manual
    return "Revis√£o Manual Necess√°ria", "REVISAO_MANUAL", "N√£o corresponde a nenhum padr√£o de ajuste ou descarte conhecido.", "N/A"


def gerar_relatorio_precificacao_realista(df_ajustes):
    """Gera relat√≥rio de precifica√ß√£o baseado nas categorias de ajuste."""
    if df_ajustes.empty:
        print("\nNenhum dado para gerar o relat√≥rio de precifica√ß√£o.")
        return

    # Focar an√°lise apenas em rotinas oficiais
    df_oficiais = df_ajustes[df_ajustes['Classifica√ß√£o'] == 'Oficiais'].copy()
    print(f"\nüìä An√°lise de Esfor√ßo focada em ROTINAS OFICIAIS: {len(df_oficiais)} pontos de {len(df_ajustes)} totais.")
    if df_oficiais.empty:
        print("Nenhuma rotina oficial encontrada para estimativa de esfor√ßo.")
        return

    summary_categorias = []
    total_dev = 0
    total_testes = 0

    # Agrupar por categoria para calcular o esfor√ßo
    contagem_categorias = df_oficiais['Categoria'].value_counts()

    for categoria_id, config in CATEGORIAS_AJUSTE.items():
        pontos = contagem_categorias.get(categoria_id, 0)
        if pontos > 0:
            if categoria_id == "REVISAO_MANUAL":
                # Custo por ponto para revis√£o manual
                esforco_dev = config["esforco_base"] * pontos
                esforco_testes = config["esforco_testes"] * pontos
            else:
                # Custo base da categoria + fator por pontos
                fator_pontos = 1 + (pontos - 1) * 0.05 # Adicional de 5% por ponto extra
                esforco_dev = round(config["esforco_base"] * fator_pontos)
                esforco_testes = round(config["esforco_testes"] * fator_pontos)

            total_dev += esforco_dev
            total_testes += esforco_testes
            summary_categorias.append({
                "Categoria": config["nome"], "Pontos Identificados": pontos,
                "Esfor√ßo Dev (h)": esforco_dev, "Esfor√ßo Testes (h)": esforco_testes,
                "Total (h)": esforco_dev + esforco_testes, "Observa√ß√£o": config["observacao"],
            })

    # Adicionar o esfor√ßo da solu√ß√£o central (base)
    esforco_central = {
        "Categoria": "Solu√ß√£o Central - Fun√ß√µes Base", "Pontos Identificados": "N/A",
        "Esfor√ßo Dev (h)": 120, "Esfor√ßo Testes (h)": 40, "Total (h)": 160,
        "Observa√ß√£o": "Desenvolvimento de fun√ß√µes centrais de valida√ß√£o e formata√ß√£o.",
    }
    summary_categorias.insert(0, esforco_central)
    total_dev += 120
    total_testes += 40
    total_geral = total_dev + total_testes

    summary_executivo = [
        {"M√©trica": "Esfor√ßo Desenvolvimento", "Valor": f"{total_dev}h"},
        {"M√©trica": "Esfor√ßo Testes QA", "Valor": f"{total_testes}h"},
        {"M√©trica": "Total Estimado", "Valor": f"{total_geral}h"},
        {"M√©trica": "Estimativa com Buffer (20%)", "Valor": f"{round(total_geral * 1.2)}h"},
        {"M√©trica": "Pontos Cr√≠ticos (Oficiais)", "Valor": len(df_oficiais)},
    ]

    try:
        with pd.ExcelWriter(ARQUIVO_SAIDA_PRECIFICACAO, engine='openpyxl') as writer:
            pd.DataFrame(summary_executivo).to_excel(writer, sheet_name='1_Summary_Executivo', index=False)
            pd.DataFrame(summary_categorias).to_excel(writer, sheet_name='2_Estimativa_Por_Categoria', index=False)
            # Adicionar aba com detalhamento dos pontos oficiais
            df_oficiais_detalhe = df_oficiais[['Arquivo', 'Linha', 'Categoria', 'Padr√£o', 'Justificativa', 'C√≥digo']]
            df_oficiais_detalhe.to_excel(writer, sheet_name='3_Detalhe_Pontos_Oficiais', index=False)
        print(f"Relat√≥rio de precifica√ß√£o salvo em: {ARQUIVO_SAIDA_PRECIFICACAO}")
        print(f"   -> Total Estimado: {total_geral}h | Com Buffer (20%): {round(total_geral * 1.2)}h")
    except Exception as e:
        print(f"ERRO ao salvar relat√≥rio de precifica√ß√£o: {e}")


def salvar_excel(df, nome_arquivo, colunas_ordem):
    """Fun√ß√£o auxiliar para salvar DataFrames em Excel com formata√ß√£o."""
    if df.empty:
        print(f"\nNenhum item para salvar em '{nome_arquivo}'.")
        return

    df_copy = df.copy()
    df_copy['Prefixo'] = df_copy['Arquivo'].str[:3].str.upper()
    df_copy['Classifica√ß√£o'] = df_copy['Arquivo'].apply(classificar_arquivo)
    df_copy['LinhaInt'] = pd.to_numeric(df_copy['Linha'])

    # Ordenar para melhor visualiza√ß√£o
    if "Categoria" in df_copy.columns:
        df_copy = df_copy.sort_values(by=['Classifica√ß√£o', 'Arquivo', 'LinhaInt'])
    else:
        df_copy = df_copy.sort_values(by=['Arquivo', 'LinhaInt'])

    colunas_presentes = df_copy.columns.tolist()
    colunas_finais = [col for col in colunas_ordem if col in colunas_presentes]
    df_final = df_copy[colunas_finais]

    try:
        df_final.to_excel(nome_arquivo, index=False, engine='openpyxl')
        print(f"Relat√≥rio salvo em: {nome_arquivo}")
    except Exception as e:
        print(f"ERRO ao salvar o arquivo '{nome_arquivo}': {e}")


def main():
    print("--- INICIANDO AN√ÅLISE DE IMPACTO DE CNPJ ALFANUM√âRICO (v4 - com deduplica√ß√£o) ---")

    VARIAVEIS_ALVO = carregar_variaveis_alvo(ARQUIVO_VARIAVEIS)
    
    # IBSRIC √© especial e n√£o uma vari√°vel comum
    is_ibsric_special = 'IBSRIC' in VARIAVEIS_ALVO
    if is_ibsric_special:
        VARIAVEIS_ALVO.remove('IBSRIC')
        print("Info: 'IBSRIC' ser√° tratado como uma chamada de sub-rotina especial.")

    print(f"Analisando o arquivo: {ARQUIVO_ENTRADA}")
    if not os.path.exists(ARQUIVO_ENTRADA):
        print(f"ERRO: Arquivo de entrada n√£o encontrado em '{ARQUIVO_ENTRADA}'")
        return

    # Etapa 1: Ler o arquivo de entrada e agrupar por linha de c√≥digo √∫nica
    linhas_unicas = {}
    variaveis_regex = r"\b(" + "|".join(re.escape(var) for var in VARIAVEIS_ALVO) + r")\b" if VARIAVEIS_ALVO else None

    print("Etapa 1: Lendo e agrupando linhas de c√≥digo √∫nicas...")
    with open(ARQUIVO_ENTRADA, 'r', encoding='utf-8', errors='ignore') as f_in:
        for linha_bruta in f_in:
            if "Searching for" in linha_bruta or not linha_bruta.strip():
                continue

            arquivo, num_linha, codigo_original = extrair_info_linha(linha_bruta.strip())
            if not arquivo:
                continue

            codigo_para_analise = re.split(r'\s*//', codigo_original)[0].strip()
            
            vars_encontradas_na_linha = set()
            if variaveis_regex:
                vars_encontradas_na_linha.update(re.findall(variaveis_regex, codigo_para_analise, re.IGNORECASE))
            
            if is_ibsric_special and re.search(r'\bIBSRIC\b', codigo_para_analise, re.IGNORECASE):
                vars_encontradas_na_linha.add('IBSRIC')
            
            if not vars_encontradas_na_linha:
                continue

            chave = (arquivo, num_linha)
            if chave not in linhas_unicas:
                linhas_unicas[chave] = {'code': codigo_original, 'vars': set()}
            
            linhas_unicas[chave]['vars'].update(vars_encontradas_na_linha)

    print(f"  - {len(linhas_unicas)} linhas de c√≥digo √∫nicas encontradas para an√°lise.")

    # Etapa 2: Classificar cada linha de c√≥digo √∫nica
    print("Etapa 2: Classificando cada linha...")
    resultados_ajustes = []
    resultados_descartados = []

    for (arquivo, num_linha), data in linhas_unicas.items():
        codigo_original = data['code']
        variaveis_encontradas = data['vars']
        codigo_para_analise = re.split(r'\s*//', codigo_original)[0].strip()
        variaveis_str = ", ".join(sorted(list(variaveis_encontradas)))
        foi_classificada = False

        # 2.1. Descarte por tipo de arquivo
        classificacao = classificar_arquivo(arquivo)
        if classificacao in ['N√£o Oficiais', 'Scripts']:
            motivo = "Rotina de Script" if classificacao == 'Scripts' else "Rotina N√£o Oficial"
            resultados_descartados.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Regra de Descarte": motivo, "C√≥digo": codigo_original
            })
            continue

        # 2.2. Caso Especial: IBSRIC
        if is_ibsric_special and 'IBSRIC' in variaveis_encontradas:
            is_comment_or_literal = re.search(r'^\s*(;.*|//.*|#;.*|rem\s)|".*\bIBSRIC\b.*"', codigo_para_analise, re.IGNORECASE)
            if not is_comment_or_literal:
                resultados_ajustes.append({
                    "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                    "Categoria": "CHAMADA_IBSRIC", "Padr√£o": "Chamada de Sub-rotina IBSRIC",
                    "Justificativa": "Chamada √† sub-rotina para escopo de teste.", "C√≥digo": codigo_original
                })
                continue

        # 2.3. Regras de Ajuste Cr√≠tico
        vars_sem_ibsric = [v for v in variaveis_encontradas if v != 'IBSRIC']
        if vars_sem_ibsric:
            vars_regex_linha = r'\b(' + '|'.join(re.escape(v) for v in vars_sem_ibsric) + r')\b'
            for nome, regex, categoria, just in REGRAS_AJUSTE_CRITICO:
                regex_com_vars = regex.replace('VARIAVEL', vars_regex_linha)
                if re.search(regex_com_vars, codigo_para_analise, re.IGNORECASE):
                    resultados_ajustes.append({
                        "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                        "Categoria": categoria, "Padr√£o": nome, "Justificativa": just, "C√≥digo": codigo_original
                    })
                    foi_classificada = True
                    break
        if foi_classificada: continue

        # 2.4. Regras de Descarte de Alta Confian√ßa
        if vars_sem_ibsric:
            vars_regex_linha = r'\b(' + '|'.join(re.escape(v) for v in vars_sem_ibsric) + r')\b'
            for motivo, regex in REGRAS_DESCARTE_CONFIANCA:
                regex_com_vars = regex.replace('VARIAVEL', vars_regex_linha)
                if re.search(regex_com_vars, codigo_para_analise, re.IGNORECASE):
                    resultados_descartados.append({
                        "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                        "Regra de Descarte": motivo, "C√≥digo": codigo_original
                    })
                    foi_classificada = True
                    break
        if foi_classificada: continue

        # 2.5. Padr√£o: Se chegou aqui e n√£o √© s√≥ IBSRIC, √© revis√£o manual
        if vars_sem_ibsric:
            resultados_ajustes.append({
                "Arquivo": arquivo, "Linha": num_linha, "Vari√°vel": variaveis_str,
                "Categoria": "REVISAO_MANUAL", "Padr√£o": "Revis√£o Manual Necess√°ria", 
                "Justificativa": "N√£o corresponde a nenhum padr√£o de ajuste ou descarte conhecido.",
                "C√≥digo": codigo_original
            })

    print(f"\nAn√°lise conclu√≠da.")
    print(f"  - Total de linhas √∫nicas analisadas: {len(linhas_unicas)}")
    print(f"  - Pontos de ajuste cr√≠tico identificados: {len(resultados_ajustes)}")
    print(f"  - Itens descartados: {len(resultados_descartados)}")

    # Gerar Relat√≥rio de Ajustes Cr√≠ticos
    if resultados_ajustes:
        df_ajustes = pd.DataFrame(resultados_ajustes)
        df_ajustes['Prefixo'] = df_ajustes['Arquivo'].str[:3].str.upper()
        df_ajustes['Classifica√ß√£o'] = df_ajustes['Arquivo'].apply(classificar_arquivo)
        colunas_ajustes = [
            "Arquivo", "Prefixo", "Classifica√ß√£o", "Linha", "Vari√°vel",
            "Categoria", "Padr√£o", "Justificativa", "C√≥digo"
        ]
        salvar_excel(df_ajustes, ARQUIVO_SAIDA_AJUSTES, colunas_ajustes)
        gerar_relatorio_precificacao_realista(df_ajustes)

    # Gerar Relat√≥rio de Descartes
    if resultados_descartados:
        df_descartados = pd.DataFrame(resultados_descartados)
        df_descartados['Prefixo'] = df_descartados['Arquivo'].str[:3].str.upper()
        df_descartados['Classifica√ß√£o'] = df_descartados['Arquivo'].apply(classificar_arquivo)
        colunas_descartes = [
            "Arquivo", "Prefixo", "Classifica√ß√£o", "Linha",
            "Vari√°vel", "Regra de Descarte", "C√≥digo"
        ]
        salvar_excel(df_descartados, ARQUIVO_SAIDA_DESCARTES, colunas_descartes)
        df_descartes_oficiais = df_descartados[df_descartados['Classifica√ß√£o'] == 'Oficiais'].copy()
        salvar_excel(df_descartes_oficiais, ARQUIVO_SAIDA_DESCARTES_OFICIAIS, colunas_descartes)

if __name__ == "__main__":
    main()